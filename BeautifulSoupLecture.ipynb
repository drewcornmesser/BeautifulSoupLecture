{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author: Drew Cornmesser**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Beautiful Soup is a Python package for parsing HTML and XML documents. It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping.\" - Wikipedia.\n",
    "\n",
    "In short: Beautiful Soup is a type of webscraper that reads the HTML code from websites and extracts it accordingly.\n",
    "\n",
    "Why is web scraping important?\n",
    " * Web scraping simplifies the process of extracting data, speeds it up by automating it and creates easy access to the scrapped data by providing it in a CSV format. In simple terms, web scraping saves you the trouble of manually downloading or copying any data and automates the whole process - towardsdatascience.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started! First for the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests # sends requests to a website\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = 'https://subslikescript.com/movie/Titanic-120338' # this is the website that we will parse\n",
    "result = requests.get(website) # this sends a request to the website to access the website and stores the website in a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = result.text # using .text gets the entire text of the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(context, 'lxml') # this get the entire xml code of the website using Beautiful Soup and stores it in a variable\n",
    "\n",
    "# uncomment this print statement to see the entire xml code of the website we scraped!\n",
    "# .prettify() makes the xml code look pretty (hence the name)\n",
    "print(soup.prettify()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where things start to get a little more difficult:\n",
    "\n",
    "Do the following things:\n",
    "1.) Navigate to the website that we are parsing: https://subslikescript.com/movie/Titanic-120338\n",
    "2.) Right click on \"Titanic (1997) - Full Transcript\"\n",
    "3.) In the dialogue - select \"Inspect\"\n",
    "\n",
    "Okay, so now you should see the html code on your screen.\n",
    "\n",
    "Beautiful Soup has a built in .find() function to find certain things in websites. This built in function utilizes the html code that you see on your screen. \n",
    "\n",
    "Look at the html code on your screen and you should see the following line of code: </article class=\"main-article\" style=\"height: auto !important;\"/> \n",
    "\n",
    "This is the snippet of code that specifies the beginning of the article. Since really all we probably care about is the article itself we want to scrape only the code that is in that 'main-article' class. To do this we use the Beautiful Soup built in .find() function. \n",
    "\n",
    "The .find() function takes in two parameters. The first parameter is known as the 'tag'. \n",
    "\n",
    "html code is essentially made up of a bunch of containers. And these containers are denoted by 'tags'. The tags denote what will be inside of that container. \n",
    "\n",
    "In the above snippet of html code the tag is 'article'. Tags can be various different things, however the type of tag is typically denoted by what comes immediately after that first '<'. So in this case, it is 'article'. All of the html code that is under that 'article' tag is what makes up the actual article. \n",
    "\n",
    "The second parameter in the .find() function denotes the class that is being used. In the above snippet of html code the class is the \"main-article\". Because 'class' is a built in Python function to make classes for coding we need a way to differentiate between 'class' in Python and 'class' in html code. To do this we use the 'class_' key word. \n",
    "\n",
    "**It should be noted that you do not need both of these parameters. The more parameters you have the more specific you are being when you tell Beautiful Soup what to scrape.**\n",
    "\n",
    "Take the below snippet of code as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this snippet of code tells Beautiful Soup to find the 'article' tag that coincides with the 'main-article' class.\n",
    "the_article = soup.find('article', class_='main-article')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we were to print 'box' we would see all of the html code that comprises the 'article'. In this case 'article' is the entire transcript of the Titanic movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(the_article.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get specific text inside of the article using the .find() function. \n",
    "\n",
    "What if we want to figure out what the title of the article is?\n",
    "\n",
    "Well, usually in html code the title of an article is depicted using the 'h1' tag. The 'h1' tag is \"used to indicate the most important (or highest-level) heading on the page\" (in this case the title). \n",
    "\n",
    "So we use the .find() function again and tell Beautiful Soup to find where that 'h1' heading is.\n",
    "\n",
    "**Note: If you 'Inspect' again you will see the line of code for that h1 tag right below that article tag that we denoted above.**\n",
    "\n",
    "Now let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.find('h1') # find where that title would be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the .get_text() function to take that html code and convert it to just text (no html code). Let's try that on our title and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see. This is indeed the title of the article. \n",
    "\n",
    "We can also do this in one line by combining the two above lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.find('h1').get_text()\n",
    "\n",
    "# uncomment this print statement and you will see the title of the article just as above.\n",
    "print(title) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now I want to see the entire script of the Titanic! \n",
    "\n",
    "How do we do that?\n",
    "\n",
    "Well we need to use a different tag. The 'div' tag is a pretty generic popular tag in html code that represents just a component or section of something. \n",
    "\n",
    "However there are going to be a LOT of 'div' tags in this html code. So what we need to do is be a little more specific in telling Beautiful Soup what else to look for when it is scraping the website. To do this we need to tell Beautiful Soup which class to look for also. \n",
    "\n",
    "Again go back and right click and 'Inspect' the website. You will see a </div class=\"full-script\"/> line of code. Everything inside of this </div/> tag is the full script and we can tell because it belongs to that \"full-script\" class. \n",
    "\n",
    "Now we probably have enough information and can tell Beautiful Soup exactly what to look for when it scrapes the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_script = soup.find('div', class_='full-script')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the full script of the Titanic stored into a variable we can use that get_text() variable to actually output the entire script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_script_text = full_script.get_text()\n",
    "print(full_script_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tada! That is the entire script of the movie Titanic.\n",
    "\n",
    "We can do the above in one line of code as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_script_text = soup.find('div', class_='full-script').get_text()\n",
    "\n",
    "print(entire_script_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to be able to save the script onto our own computers! Well we can just send the script to a txt file for our own personal reasons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{title}.txt', 'w', encoding=\"utf-8\") as file:\n",
    "    file.write(full_script_text) # can also use the entire_script_text variable they are the same thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see the entire script of the Titanic saved as 'Titanic (1997) - full transcript.txt' saved on your computer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
